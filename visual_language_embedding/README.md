# ChaLearn-SLR = Visual Language Embedding

This repo is used for training, testing, and predicting visual language embeddings.

## Code Description

### Data generation

#### create_training_set.py
This script generates training and validation data from images of hand crops (generated by _open_pose_hand_grabber.py_)
and hand clustering (generated by _hand_clustering.py_).

`python create_training_set.py /home/data/train_hand_images.h5 /home/data/hand_clusters_v03_05.p /home/data/train_hands.h5 /home/data/val_hands.h5`

#### create_training_set_from_ref_data.py
This script generates training and validation data from images of hand crops that have been manually divided into
clusters. The clusters are stored on disk (depth-of-one structure) and are named after the name of the folder.

`python create_training_set_from_ref_data.py /home/data/training_hands /home/data/train_hands.h5`

### Training

#### train.py
Training of VLE model.

`python train.py /home/data/train_hands.h5 /home/data/val_hands.h5 mobilenet 39 /home/data/models/vle/vle_mobilenet_pretrained_aug_ref_images.pth`

#### predict.py
Predicting of VLE model.

`python predict.py /home/data/test_hands.h5 /home/data/models/vle/vle_mobilenet_pretrained_normalized_resized_aug_ref_images_39.pthepoch_9.tar
 39 /home/data/vle_hand_crops_test_v2.h5 --open_pose_h5 /home/data/train_json_keypoints-raw.h5 --resize 224 --min_conf 0.55`